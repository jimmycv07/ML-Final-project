{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNjS9xzMFYg7rhkGHpwE3Mq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_POH_Giny_R","executionInfo":{"status":"ok","timestamp":1673336726923,"user_tz":-480,"elapsed":2883,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"ca0551c8-e675-444a-8542-655e4f110b1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","Downloading tabular-playground-series-aug-2022.zip to /content\n"," 88% 2.00M/2.27M [00:00<00:00, 3.01MB/s]\n","100% 2.27M/2.27M [00:00<00:00, 2.92MB/s]\n","Archive:  tabular-playground-series-aug-2022.zip\n","  inflating: sample_submission.csv   \n","  inflating: test.csv                \n","  inflating: train.csv               \n","/content/kaggle.json\n","/content/0711257_model.pkl\n","/content/tabular-playground-series-aug-2022.zip\n","/content/sample_submission.csv\n","/content/train.csv\n","/content/test.csv\n","/content/.config/config_sentinel\n","/content/.config/.last_update_check.json\n","/content/.config/gce\n","/content/.config/.last_opt_in_prompt.yaml\n","/content/.config/active_config\n","/content/.config/.last_survey_prompt.yaml\n","/content/.config/logs/2023.01.05/14.32.48.311993.log\n","/content/.config/logs/2023.01.05/14.34.01.063009.log\n","/content/.config/logs/2023.01.05/14.34.00.192801.log\n","/content/.config/logs/2023.01.05/14.33.30.524625.log\n","/content/.config/logs/2023.01.05/14.32.18.784307.log\n","/content/.config/logs/2023.01.05/14.33.16.757082.log\n","/content/.config/configurations/config_default\n","/content/sample_data/anscombe.json\n","/content/sample_data/README.md\n","/content/sample_data/mnist_train_small.csv\n","/content/sample_data/mnist_test.csv\n","/content/sample_data/california_housing_test.csv\n","/content/sample_data/california_housing_train.csv\n"]}],"source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load\n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the read-only \"../input/\" directory\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n","# !kaggle competitions download -c tabular-playground-series-aug-2022\n","# !unzip tabular-playground-series-aug-2022\n","# for dirname, _, filenames in os.walk('/content'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","source":["test = pd.read_csv('/content/test.csv')\n","train = pd.read_csv('/content/train.csv')\n","submission = pd.read_csv('/content/sample_submission.csv')\n","model_path = \"/content/0711257_model.pkl\""],"metadata":{"id":"-apNVWLDpH5W","executionInfo":{"status":"ok","timestamp":1673336726924,"user_tz":-480,"elapsed":2,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install feature_engine\n","!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkNjNMqSoVli","executionInfo":{"status":"ok","timestamp":1673336737246,"user_tz":-480,"elapsed":10324,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"cc390767-da82-4cc9-9f6b-71125c00671d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting feature_engine\n","  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n","Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Installing collected packages: feature_engine\n","Successfully installed feature_engine-1.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow_addons\n","Successfully installed tensorflow_addons-0.19.0\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import gc; gc.enable()\n","from lightgbm import LGBMClassifier\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import roc_auc_score\n","from sklearn.naive_bayes import GaussianNB\n","from feature_engine.encoding import WoEEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression, HuberRegressor\n","import warnings; warnings.filterwarnings(\"ignore\")\n","from tensorflow.keras import Sequential  \n","from tensorflow.keras import layers\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","pd.options.display.max_columns = 999"],"metadata":{"id":"I9gZk_Q4pHBA","executionInfo":{"status":"ok","timestamp":1673336741572,"user_tz":-480,"elapsed":4327,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["with open(model_path, 'rb') as fp:\n","    models = pickle.load(fp)"],"metadata":{"id":"GL90CclzpIAw","executionInfo":{"status":"ok","timestamp":1673336756081,"user_tz":-480,"elapsed":14512,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["folds_dict = {'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n","               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n","               'Fold 3': [['B', 'C', 'E'], ['A', 'D']],\n","               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n","               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n","               'Fold 6': [['A', 'C', 'E'], ['B', 'D']],\n","               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n","               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n","               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n","               'Fold 10': [['A', 'B', 'C'], ['D', 'E']]}\n","print(folds_dict[\"Fold 1\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"882qgMt0EARu","executionInfo":{"status":"ok","timestamp":1673336756082,"user_tz":-480,"elapsed":14,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"f7cce060-c3b1-40e8-905d-b441a6202eeb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[['C', 'D', 'E'], ['A', 'B']]\n"]}]},{"cell_type":"code","source":["tf.keras.utils.set_random_seed(42)\n","def preprocessing(df_train, df_test):\n","    data = pd.concat([df_train, df_test])\n","    features = 0\n","    \n","    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n","    data['m4_missing'] = data['measurement_4'].isnull().astype(np.int8)\n","    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n","    data['area'] = data['attribute_2'] * data['attribute_3']\n","\n","    # dictionnary of dictionnaries (for the 11 best correlated measurement columns), \n","    # we will use the dictionnaries below to select the best correlated columns according to the product code)\n","    # Only for 'measurement_17' we make a 'manual' selection :\n","    full_fill_dict ={}\n","    full_fill_dict['measurement_17'] = {\n","        'A': ['measurement_5','measurement_6','measurement_8'],\n","        'B': ['measurement_4','measurement_5','measurement_7'],\n","        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n","        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n","        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n","        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n","        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n","        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n","        'I': ['measurement_3','measurement_7','measurement_8']\n","    }\n","\n","    # collect the name of the next 10 best measurement columns sorted by correlation (except 17 already done above):\n","    col = [col for col in df_test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n","    # print(col)\n","    a = []\n","    b =[]\n","\n","    #sort the measurement as its correlation among measurement_3-17\n","    corr = np.absolute(data.drop(col, axis=1).corr())\n","    for x in range(3,17):\n","        corrr = corr[f'measurement_{x}'].sort_values(ascending=False)\n","        a.append(np.round(np.sum(corrr[1:4]),3)) # we add the 3 first lines of the correlation values to get the \"most correlated\"\n","        b.append(f'measurement_{x}')\n","    print(a,b)\n","    c = pd.DataFrame()\n","    c['Selected columns'] = b\n","    c['correlation total'] = a\n","    c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\n","    print(f'Columns selected by correlation sum of the 3 first rows : ')\n","    display(c.head(15))\n","\n","    for i in range(10): \n","        measurement_col = c.iloc[i, 0]\n","        fill_dict = {}\n","        for x in data.product_code.unique() : \n","            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n","            measurement_col_dic = {}\n","            fill_dict[x] = corr[1:5].index.tolist()\n","        full_fill_dict[measurement_col] = fill_dict\n","\n","    feature = [f for f in data.columns if f.startswith('measurement') or f == 'loading']\n","    print('failure' in feature)\n","    nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().sum()]\n","    for code in data.product_code.unique():\n","        total_na_filled_by_linear_model = 0\n","        print(f'\\n-------- Product code {code} ----------\\n')\n","        print(f'filled by linear model :')\n","        for measurement_col in list(full_fill_dict.keys()):\n","            tmp = data[data.product_code == code]\n","            column = full_fill_dict[measurement_col][code]\n","            tmp_train = tmp[column+[measurement_col]].dropna(how='any') # a na in row then drop\n","            '''\n","            every column should have value && measurement should not\n","            '''\n","            tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n","            model = HuberRegressor(epsilon=1.9)\n","            model.fit(tmp_train[column], tmp_train[measurement_col])\n","            data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n","            print(f'{measurement_col} : {len(tmp_test)}')\n","            total_na_filled_by_linear_model += len(tmp_test)\n","            # break\n","        # others NA columns:\n","        # print(data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum())\n","        # print(data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum().sum())\n","        NA = data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum().sum()\n","        '''\n","        KNNImputer\n","        '''\n","        model1 = KNNImputer(n_neighbors=3)\n","        data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n","        print(f'\\n{total_na_filled_by_linear_model} filled by linear model ') \n","        print(f'{NA} filled by KNN ')\n","        # break\n","    data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n","    data['measurement_std'] = data[[f'measurement_{i}' for i in range(3, 17)]].std(axis=1)\n","    data['measurement_median'] = data[[f'measurement_{i}' for i in range(3, 17)]].median(axis=1)\n","    data['measurement_max'] = data[[f'measurement_{i}' for i in range(3, 17)]].max(axis=1)\n","    data['measurement_min'] = data[[f'measurement_{i}' for i in range(3, 17)]].min(axis=1)\n","    data['measurement_skew'] = data[[f'measurement_{i}' for i in range(3, 17)]].skew(axis=1)\n","    \n","    \n","    df_train = data.iloc[:df_train.shape[0],:]\n","    df_test = data.iloc[df_train.shape[0]:,:]\n","\n","    '''\n","    drop attribute_1 cuz they have different unique values between train and test\n","    '''\n","    woe_encoder = WoEEncoder(variables=['attribute_0'])\n","    woe_encoder.fit(df_train, df_train['failure'])\n","    df_train = woe_encoder.transform(df_train)\n","    df_test = woe_encoder.transform(df_test)\n","    return df_train, df_test\n","df_train, df_test = preprocessing(train, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IVG2MBxOuG0q","executionInfo":{"status":"ok","timestamp":1673336773197,"user_tz":-480,"elapsed":17128,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"6e0e73f5-aa84-42ad-dcd8-17f44923b119"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.092, 0.331, 0.386, 0.365, 0.336, 0.454, 0.201, 0.3, 0.395, 0.145, 0.188, 0.225, 0.301, 0.252] ['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16']\n","Columns selected by correlation sum of the 3 first rows : \n"]},{"output_type":"display_data","data":{"text/plain":["   Selected columns  correlation total\n","0     measurement_8              0.454\n","1    measurement_11              0.395\n","2     measurement_5              0.386\n","3     measurement_6              0.365\n","4     measurement_7              0.336\n","5     measurement_4              0.331\n","6    measurement_15              0.301\n","7    measurement_10              0.300\n","8    measurement_16              0.252\n","9    measurement_14              0.225\n","10    measurement_9              0.201\n","11   measurement_13              0.188\n","12   measurement_12              0.145\n","13    measurement_3              0.092"],"text/html":["\n","  <div id=\"df-d6c2528c-74e4-46d9-9988-ad007fb651d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Selected columns</th>\n","      <th>correlation total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>measurement_8</td>\n","      <td>0.454</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>measurement_11</td>\n","      <td>0.395</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>measurement_5</td>\n","      <td>0.386</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>measurement_6</td>\n","      <td>0.365</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>measurement_7</td>\n","      <td>0.336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>measurement_4</td>\n","      <td>0.331</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>measurement_15</td>\n","      <td>0.301</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>measurement_10</td>\n","      <td>0.300</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>measurement_16</td>\n","      <td>0.252</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>measurement_14</td>\n","      <td>0.225</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>measurement_9</td>\n","      <td>0.201</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>measurement_13</td>\n","      <td>0.188</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>measurement_12</td>\n","      <td>0.145</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>measurement_3</td>\n","      <td>0.092</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6c2528c-74e4-46d9-9988-ad007fb651d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d6c2528c-74e4-46d9-9988-ad007fb651d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6c2528c-74e4-46d9-9988-ad007fb651d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["False\n","\n","-------- Product code A ----------\n","\n","filled by linear model :\n","measurement_17 : 386\n","measurement_8 : 175\n","measurement_11 : 225\n","measurement_5 : 113\n","measurement_6 : 146\n","measurement_7 : 166\n","measurement_4 : 79\n","measurement_15 : 273\n","measurement_10 : 209\n","measurement_16 : 293\n","measurement_14 : 237\n","\n","2302 filled by linear model \n","1547 filled by KNN \n","\n","-------- Product code B ----------\n","\n","filled by linear model :\n","measurement_17 : 418\n","measurement_8 : 165\n","measurement_11 : 220\n","measurement_5 : 90\n","measurement_6 : 106\n","measurement_7 : 176\n","measurement_4 : 80\n","measurement_15 : 294\n","measurement_10 : 197\n","measurement_16 : 358\n","measurement_14 : 330\n","\n","2434 filled by linear model \n","1541 filled by KNN \n","\n","-------- Product code C ----------\n","\n","filled by linear model :\n","measurement_17 : 391\n","measurement_8 : 211\n","measurement_11 : 231\n","measurement_5 : 141\n","measurement_6 : 150\n","measurement_7 : 140\n","measurement_4 : 110\n","measurement_15 : 319\n","measurement_10 : 262\n","measurement_16 : 343\n","measurement_14 : 340\n","\n","2638 filled by linear model \n","1706 filled by KNN \n","\n","-------- Product code D ----------\n","\n","filled by linear model :\n","measurement_17 : 398\n","measurement_8 : 146\n","measurement_11 : 265\n","measurement_5 : 87\n","measurement_6 : 118\n","measurement_7 : 146\n","measurement_4 : 88\n","measurement_15 : 313\n","measurement_10 : 174\n","measurement_16 : 338\n","measurement_14 : 316\n","\n","2389 filled by linear model \n","1584 filled by KNN \n","\n","-------- Product code E ----------\n","\n","filled by linear model :\n","measurement_17 : 429\n","measurement_8 : 177\n","measurement_11 : 244\n","measurement_5 : 116\n","measurement_6 : 127\n","measurement_7 : 185\n","measurement_4 : 105\n","measurement_15 : 315\n","measurement_10 : 193\n","measurement_16 : 316\n","measurement_14 : 297\n","\n","2504 filled by linear model \n","1628 filled by KNN \n","\n","-------- Product code F ----------\n","\n","filled by linear model :\n","measurement_17 : 420\n","measurement_8 : 194\n","measurement_11 : 226\n","measurement_5 : 90\n","measurement_6 : 140\n","measurement_7 : 147\n","measurement_4 : 91\n","measurement_15 : 333\n","measurement_10 : 186\n","measurement_16 : 356\n","measurement_14 : 348\n","\n","2531 filled by linear model \n","1542 filled by KNN \n","\n","-------- Product code G ----------\n","\n","filled by linear model :\n","measurement_17 : 373\n","measurement_8 : 188\n","measurement_11 : 221\n","measurement_5 : 104\n","measurement_6 : 146\n","measurement_7 : 145\n","measurement_4 : 93\n","measurement_15 : 299\n","measurement_10 : 226\n","measurement_16 : 343\n","measurement_14 : 268\n","\n","2406 filled by linear model \n","1518 filled by KNN \n","\n","-------- Product code H ----------\n","\n","filled by linear model :\n","measurement_17 : 361\n","measurement_8 : 147\n","measurement_11 : 205\n","measurement_5 : 112\n","measurement_6 : 121\n","measurement_7 : 161\n","measurement_4 : 75\n","measurement_15 : 299\n","measurement_10 : 217\n","measurement_16 : 340\n","measurement_14 : 283\n","\n","2321 filled by linear model \n","1562 filled by KNN \n","\n","-------- Product code I ----------\n","\n","filled by linear model :\n","measurement_17 : 377\n","measurement_8 : 192\n","measurement_11 : 209\n","measurement_5 : 119\n","measurement_6 : 132\n","measurement_7 : 136\n","measurement_4 : 89\n","measurement_15 : 350\n","measurement_10 : 246\n","measurement_16 : 294\n","measurement_14 : 283\n","\n","2427 filled by linear model \n","1402 filled by KNN \n"]}]},{"cell_type":"code","source":["features = ['loading', 'attribute_0', 'measurement_17',\n","            'measurement_0', 'measurement_1', 'measurement_2',\n","            'area', 'm3_missing',\n","            'm4_missing', 'm5_missing', 'measurement_avg',\n","            'measurement_std', 'measurement_median','measurement_min',\n","            'measurement_skew']\n","features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gdp_1EmUD7eo","executionInfo":{"status":"ok","timestamp":1673336773198,"user_tz":-480,"elapsed":12,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"b2d4aadb-2a97-4565-c03d-6fc93a6d1fb4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['loading',\n"," 'attribute_0',\n"," 'measurement_17',\n"," 'measurement_0',\n"," 'measurement_1',\n"," 'measurement_2',\n"," 'area',\n"," 'm3_missing',\n"," 'm4_missing',\n"," 'm5_missing',\n"," 'measurement_avg',\n"," 'measurement_std',\n"," 'measurement_median',\n"," 'measurement_min',\n"," 'measurement_skew']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["pred = np.zeros((df_test.shape[0], 1))\n","weight = models[-1]\n","for i, fold in enumerate(folds_dict.keys()):\n","  model = models[i]\n","  pred += model.predict(df_test[features].values).reshape(-1, 1) * weight[i]\n","pred /= np.sum(weight)\n","submission['failure'] = pred\n","submission.to_csv('0711257_submission.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bApl_ZDcpIHN","executionInfo":{"status":"ok","timestamp":1673336793198,"user_tz":-480,"elapsed":20011,"user":{"displayName":"葉長瀚","userId":"11322655115775321152"}},"outputId":"e4f64d2a-f4f8-4094-a307-a60b9da64c33"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["650/650 [==============================] - 2s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n"]}]}]}