{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuwgqe+j+pUQPO+pe4t7EA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":55,"metadata":{"id":"D4TtEgfCQ3nJ","executionInfo":{"status":"ok","timestamp":1673339894390,"user_tz":-480,"elapsed":504,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"outputs":[],"source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load\n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the read-only \"../input/\" directory\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n","# !kaggle competitions download -c tabular-playground-series-aug-2022\n","# !unzip tabular-playground-series-aug-2022\n","# for dirname, _, filenames in os.walk('/content'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","source":["train = pd.read_csv('/content/train.csv')\n","test = pd.read_csv('/content/test.csv')\n","submission = pd.read_csv('/content/sample_submission.csv')"],"metadata":{"id":"_RoQAcx6VrdM","executionInfo":{"status":"ok","timestamp":1673339895337,"user_tz":-480,"elapsed":380,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["!pip install feature_engine\n","!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9k0x-sTUot1","executionInfo":{"status":"ok","timestamp":1673339901072,"user_tz":-480,"elapsed":5738,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"e4b743ce-57b8-4a51-8697-1f5511cf73c7"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: feature_engine in /usr/local/lib/python3.8/dist-packages (1.5.2)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n","Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import gc; gc.enable()\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import roc_auc_score\n","from feature_engine.encoding import WoEEncoder\n","from sklearn.linear_model import HuberRegressor\n","import warnings; warnings.filterwarnings(\"ignore\")\n","from tensorflow.keras import Sequential  \n","from tensorflow.keras import layers\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","pd.options.display.max_columns = 999"],"metadata":{"id":"zyaS4sU0Vabh","executionInfo":{"status":"ok","timestamp":1673339901073,"user_tz":-480,"elapsed":13,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["train.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKB1gO9bV1i-","executionInfo":{"status":"ok","timestamp":1673339901073,"user_tz":-480,"elapsed":13,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"2703bdb5-dbdd-49c6-d98f-4d63a0a0e8bd"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                   0\n","product_code         0\n","loading            250\n","attribute_0          0\n","attribute_1          0\n","attribute_2          0\n","attribute_3          0\n","measurement_0        0\n","measurement_1        0\n","measurement_2        0\n","measurement_3      381\n","measurement_4      538\n","measurement_5      676\n","measurement_6      796\n","measurement_7      937\n","measurement_8     1048\n","measurement_9     1227\n","measurement_10    1300\n","measurement_11    1468\n","measurement_12    1601\n","measurement_13    1774\n","measurement_14    1874\n","measurement_15    2009\n","measurement_16    2110\n","measurement_17    2284\n","failure              0\n","dtype: int64"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["print(np.mean(train[\"failure\"]))\n","print(np.max(train[\"failure\"]))\n","print(np.min(train[\"failure\"]))\n","print(np.std(train[\"failure\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzWWphYGRkDM","executionInfo":{"status":"ok","timestamp":1673339901073,"user_tz":-480,"elapsed":11,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"eb7db2c7-ea90-49f8-f0b5-acb6af3cebe3"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["0.21260820474219044\n","1\n","0\n","0.4091527294525765\n"]}]},{"cell_type":"code","source":["test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kalJbTfOc71J","executionInfo":{"status":"ok","timestamp":1673339901074,"user_tz":-480,"elapsed":11,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"39cc9bcf-4e50-4dea-d54a-a405c2a3e7b7"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                   0\n","product_code         0\n","loading            223\n","attribute_0          0\n","attribute_1          0\n","attribute_2          0\n","attribute_3          0\n","measurement_0        0\n","measurement_1        0\n","measurement_2        0\n","measurement_3      329\n","measurement_4      409\n","measurement_5      508\n","measurement_6      624\n","measurement_7      720\n","measurement_8      846\n","measurement_9      904\n","measurement_10    1067\n","measurement_11    1136\n","measurement_12    1240\n","measurement_13    1303\n","measurement_14    1440\n","measurement_15    1542\n","measurement_16    1678\n","measurement_17    1740\n","dtype: int64"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["print(train['product_code'].value_counts())\n","print(test['product_code'].value_counts())\n","train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"Vg6_CG5ZWQN0","executionInfo":{"status":"ok","timestamp":1673339901074,"user_tz":-480,"elapsed":11,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"87e13d22-f9eb-451d-b166-f98612173d11"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["C    5765\n","E    5343\n","B    5250\n","D    5112\n","A    5100\n","Name: product_code, dtype: int64\n","F    5422\n","I    5228\n","G    5107\n","H    5018\n","Name: product_code, dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n","0   0            A    80.10  material_7  material_8            9            5   \n","1   1            A    84.89  material_7  material_8            9            5   \n","2   2            A    82.43  material_7  material_8            9            5   \n","3   3            A   101.07  material_7  material_8            9            5   \n","4   4            A   188.06  material_7  material_8            9            5   \n","\n","   measurement_0  measurement_1  measurement_2  measurement_3  measurement_4  \\\n","0              7              8              4         18.040         12.518   \n","1             14              3              3         18.213         11.540   \n","2             12              1              5         18.057         11.652   \n","3             13              2              6         17.295         11.188   \n","4              9              2              8         19.346         12.950   \n","\n","   measurement_5  measurement_6  measurement_7  measurement_8  measurement_9  \\\n","0         15.748         19.292         11.739         20.155         10.672   \n","1         17.717         17.893         12.748         17.889         12.448   \n","2         16.738         18.240         12.718         18.288         12.715   \n","3         18.576         18.339         12.583         19.060         12.471   \n","4         16.990         15.746         11.306         18.093         10.337   \n","\n","   measurement_10  measurement_11  measurement_12  measurement_13  \\\n","0          15.859          17.594          15.193          15.029   \n","1          17.947          17.915          11.755          14.732   \n","2          15.607             NaN          13.798          16.711   \n","3          16.346          18.377          10.020          15.250   \n","4          17.082          19.932          12.428          16.182   \n","\n","   measurement_14  measurement_15  measurement_16  measurement_17  failure  \n","0             NaN          13.034          14.684         764.100        0  \n","1          15.425          14.395          15.631         682.057        0  \n","2          18.631          14.094          17.946         663.376        0  \n","3          15.562          16.154          17.172         826.282        0  \n","4          12.760          13.153          16.412         579.885        0  "],"text/html":["\n","  <div id=\"df-e5069e28-284a-4b9f-848e-3ca5ba325093\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>measurement_3</th>\n","      <th>measurement_4</th>\n","      <th>measurement_5</th>\n","      <th>measurement_6</th>\n","      <th>measurement_7</th>\n","      <th>measurement_8</th>\n","      <th>measurement_9</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>failure</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>80.10</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>18.040</td>\n","      <td>12.518</td>\n","      <td>15.748</td>\n","      <td>19.292</td>\n","      <td>11.739</td>\n","      <td>20.155</td>\n","      <td>10.672</td>\n","      <td>15.859</td>\n","      <td>17.594</td>\n","      <td>15.193</td>\n","      <td>15.029</td>\n","      <td>NaN</td>\n","      <td>13.034</td>\n","      <td>14.684</td>\n","      <td>764.100</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>84.89</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>14</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>18.213</td>\n","      <td>11.540</td>\n","      <td>17.717</td>\n","      <td>17.893</td>\n","      <td>12.748</td>\n","      <td>17.889</td>\n","      <td>12.448</td>\n","      <td>17.947</td>\n","      <td>17.915</td>\n","      <td>11.755</td>\n","      <td>14.732</td>\n","      <td>15.425</td>\n","      <td>14.395</td>\n","      <td>15.631</td>\n","      <td>682.057</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>82.43</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>18.057</td>\n","      <td>11.652</td>\n","      <td>16.738</td>\n","      <td>18.240</td>\n","      <td>12.718</td>\n","      <td>18.288</td>\n","      <td>12.715</td>\n","      <td>15.607</td>\n","      <td>NaN</td>\n","      <td>13.798</td>\n","      <td>16.711</td>\n","      <td>18.631</td>\n","      <td>14.094</td>\n","      <td>17.946</td>\n","      <td>663.376</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>101.07</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>17.295</td>\n","      <td>11.188</td>\n","      <td>18.576</td>\n","      <td>18.339</td>\n","      <td>12.583</td>\n","      <td>19.060</td>\n","      <td>12.471</td>\n","      <td>16.346</td>\n","      <td>18.377</td>\n","      <td>10.020</td>\n","      <td>15.250</td>\n","      <td>15.562</td>\n","      <td>16.154</td>\n","      <td>17.172</td>\n","      <td>826.282</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>188.06</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>19.346</td>\n","      <td>12.950</td>\n","      <td>16.990</td>\n","      <td>15.746</td>\n","      <td>11.306</td>\n","      <td>18.093</td>\n","      <td>10.337</td>\n","      <td>17.082</td>\n","      <td>19.932</td>\n","      <td>12.428</td>\n","      <td>16.182</td>\n","      <td>12.760</td>\n","      <td>13.153</td>\n","      <td>16.412</td>\n","      <td>579.885</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5069e28-284a-4b9f-848e-3ca5ba325093')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e5069e28-284a-4b9f-848e-3ca5ba325093 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e5069e28-284a-4b9f-848e-3ca5ba325093');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["print(train.columns)\n","print(test.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j569nrqPWvep","executionInfo":{"status":"ok","timestamp":1673339901074,"user_tz":-480,"elapsed":9,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"5bef0517-9e5a-4359-ef09-d27e62108ef7"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['id', 'product_code', 'loading', 'attribute_0', 'attribute_1',\n","       'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1',\n","       'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5',\n","       'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9',\n","       'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13',\n","       'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17',\n","       'failure'],\n","      dtype='object')\n","Index(['id', 'product_code', 'loading', 'attribute_0', 'attribute_1',\n","       'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1',\n","       'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5',\n","       'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9',\n","       'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13',\n","       'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["folds_dict = {'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n","               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n","               'Fold 3': [['B', 'C', 'E'], ['A', 'D']],\n","               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n","               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n","               'Fold 6': [['A', 'C', 'E'], ['B', 'D']],\n","               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n","               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n","               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n","               'Fold 10': [['A', 'B', 'C'], ['D', 'E']]}\n","print(folds_dict[\"Fold 1\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxsnVxysXFJV","executionInfo":{"status":"ok","timestamp":1673339901074,"user_tz":-480,"elapsed":9,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"4835a9cc-cc95-4e3a-a28a-8b227036a565"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["[['C', 'D', 'E'], ['A', 'B']]\n"]}]},{"cell_type":"code","source":["tf.keras.utils.set_random_seed(42)\n","def preprocessing(df_train, df_test):\n","    data = pd.concat([df_train, df_test])\n","    features = 0\n","    \n","    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n","    data['m4_missing'] = data['measurement_4'].isnull().astype(np.int8)\n","    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n","    data['area'] = data['attribute_2'] * data['attribute_3']\n","\n","    # dictionnary of dictionnaries (for the 11 best correlated measurement columns), \n","    # we will use the dictionnaries below to select the best correlated columns according to the product code)\n","    # Only for 'measurement_17' we make a 'manual' selection :\n","    full_fill_dict ={}\n","    full_fill_dict['measurement_17'] = {\n","        'A': ['measurement_5','measurement_6','measurement_8'],\n","        'B': ['measurement_4','measurement_5','measurement_7'],\n","        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n","        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n","        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n","        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n","        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n","        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n","        'I': ['measurement_3','measurement_7','measurement_8']\n","    }\n","\n","    # collect the name of the next 10 best measurement columns sorted by correlation (except 17 already done above):\n","    col = [col for col in df_test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n","    # print(col)\n","    a = []\n","    b =[]\n","\n","    #sort the measurement as its correlation among measurement_3-17\n","    corr = np.absolute(data.drop(col, axis=1).corr())\n","    for x in range(3,17):\n","        corrr = corr[f'measurement_{x}'].sort_values(ascending=False)\n","        a.append(np.round(np.sum(corrr[1:4]),3)) # we add the 3 first lines of the correlation values to get the \"most correlated\"\n","        b.append(f'measurement_{x}')\n","    print(a,b)\n","    c = pd.DataFrame()\n","    c['Selected columns'] = b\n","    c['correlation total'] = a\n","    c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\n","    print(f'Columns selected by correlation sum of the 3 first rows : ')\n","    display(c.head(15))\n","\n","    for i in range(10): \n","        measurement_col = c.iloc[i, 0]\n","        fill_dict = {}\n","        for x in data.product_code.unique() : \n","            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n","            measurement_col_dic = {}\n","            fill_dict[x] = corr[1:5].index.tolist()\n","        full_fill_dict[measurement_col] = fill_dict\n","\n","    feature = [f for f in data.columns if f.startswith('measurement') or f == 'loading']\n","    print('failure' in feature)\n","    nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().sum()]\n","    for code in data.product_code.unique():\n","        total_na_filled_by_linear_model = 0\n","        print(f'\\n-------- Product code {code} ----------\\n')\n","        print(f'filled by linear model :')\n","        for measurement_col in list(full_fill_dict.keys()):\n","            tmp = data[data.product_code == code]\n","            column = full_fill_dict[measurement_col][code]\n","            tmp_train = tmp[column+[measurement_col]].dropna(how='any') # a na in row then drop\n","            '''\n","            every column should have value && measurement should not\n","            '''\n","            tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n","            model = HuberRegressor(epsilon=1.9)\n","            model.fit(tmp_train[column], tmp_train[measurement_col])\n","            data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n","            print(f'{measurement_col} : {len(tmp_test)}')\n","            total_na_filled_by_linear_model += len(tmp_test)\n","            # break\n","        # others NA columns:\n","        # print(data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum())\n","        # print(data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum().sum())\n","        NA = data.loc[data[\"product_code\"] == code, nullValue_cols].isnull().sum().sum()\n","        '''\n","        KNNImputer\n","        '''\n","        model1 = KNNImputer(n_neighbors=3)\n","        data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n","        print(f'\\n{total_na_filled_by_linear_model} filled by linear model ') \n","        print(f'{NA} filled by KNN ')\n","        # break\n","    data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n","    data['measurement_std'] = data[[f'measurement_{i}' for i in range(3, 17)]].std(axis=1)\n","    data['measurement_median'] = data[[f'measurement_{i}' for i in range(3, 17)]].median(axis=1)\n","    data['measurement_max'] = data[[f'measurement_{i}' for i in range(3, 17)]].max(axis=1)\n","    data['measurement_min'] = data[[f'measurement_{i}' for i in range(3, 17)]].min(axis=1)\n","    data['measurement_skew'] = data[[f'measurement_{i}' for i in range(3, 17)]].skew(axis=1)\n","    \n","    \n","    df_train = data.iloc[:df_train.shape[0],:]\n","    df_test = data.iloc[df_train.shape[0]:,:]\n","\n","    '''\n","    drop attribute_1 cuz they have different unique values between train and test\n","    '''\n","    woe_encoder = WoEEncoder(variables=['attribute_0'])\n","    woe_encoder.fit(df_train, df_train['failure'])\n","    df_train = woe_encoder.transform(df_train)\n","    df_test = woe_encoder.transform(df_test)\n","    return df_train, df_test\n","df_train, df_test = preprocessing(train, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DdP2BoDTZU4G","executionInfo":{"status":"ok","timestamp":1673339923823,"user_tz":-480,"elapsed":22757,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"4b864bb0-b9b3-41e2-eebe-49793708a32f"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.092, 0.331, 0.386, 0.365, 0.336, 0.454, 0.201, 0.3, 0.395, 0.145, 0.188, 0.225, 0.301, 0.252] ['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16']\n","Columns selected by correlation sum of the 3 first rows : \n"]},{"output_type":"display_data","data":{"text/plain":["   Selected columns  correlation total\n","0     measurement_8              0.454\n","1    measurement_11              0.395\n","2     measurement_5              0.386\n","3     measurement_6              0.365\n","4     measurement_7              0.336\n","5     measurement_4              0.331\n","6    measurement_15              0.301\n","7    measurement_10              0.300\n","8    measurement_16              0.252\n","9    measurement_14              0.225\n","10    measurement_9              0.201\n","11   measurement_13              0.188\n","12   measurement_12              0.145\n","13    measurement_3              0.092"],"text/html":["\n","  <div id=\"df-f5c3f279-16d2-44b9-99e0-71d9a709bd41\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Selected columns</th>\n","      <th>correlation total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>measurement_8</td>\n","      <td>0.454</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>measurement_11</td>\n","      <td>0.395</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>measurement_5</td>\n","      <td>0.386</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>measurement_6</td>\n","      <td>0.365</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>measurement_7</td>\n","      <td>0.336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>measurement_4</td>\n","      <td>0.331</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>measurement_15</td>\n","      <td>0.301</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>measurement_10</td>\n","      <td>0.300</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>measurement_16</td>\n","      <td>0.252</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>measurement_14</td>\n","      <td>0.225</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>measurement_9</td>\n","      <td>0.201</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>measurement_13</td>\n","      <td>0.188</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>measurement_12</td>\n","      <td>0.145</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>measurement_3</td>\n","      <td>0.092</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5c3f279-16d2-44b9-99e0-71d9a709bd41')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f5c3f279-16d2-44b9-99e0-71d9a709bd41 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f5c3f279-16d2-44b9-99e0-71d9a709bd41');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["False\n","\n","-------- Product code A ----------\n","\n","filled by linear model :\n","measurement_17 : 386\n","measurement_8 : 175\n","measurement_11 : 225\n","measurement_5 : 113\n","measurement_6 : 146\n","measurement_7 : 166\n","measurement_4 : 79\n","measurement_15 : 273\n","measurement_10 : 209\n","measurement_16 : 293\n","measurement_14 : 237\n","\n","2302 filled by linear model \n","1547 filled by KNN \n","\n","-------- Product code B ----------\n","\n","filled by linear model :\n","measurement_17 : 418\n","measurement_8 : 165\n","measurement_11 : 220\n","measurement_5 : 90\n","measurement_6 : 106\n","measurement_7 : 176\n","measurement_4 : 80\n","measurement_15 : 294\n","measurement_10 : 197\n","measurement_16 : 358\n","measurement_14 : 330\n","\n","2434 filled by linear model \n","1541 filled by KNN \n","\n","-------- Product code C ----------\n","\n","filled by linear model :\n","measurement_17 : 391\n","measurement_8 : 211\n","measurement_11 : 231\n","measurement_5 : 141\n","measurement_6 : 150\n","measurement_7 : 140\n","measurement_4 : 110\n","measurement_15 : 319\n","measurement_10 : 262\n","measurement_16 : 343\n","measurement_14 : 340\n","\n","2638 filled by linear model \n","1706 filled by KNN \n","\n","-------- Product code D ----------\n","\n","filled by linear model :\n","measurement_17 : 398\n","measurement_8 : 146\n","measurement_11 : 265\n","measurement_5 : 87\n","measurement_6 : 118\n","measurement_7 : 146\n","measurement_4 : 88\n","measurement_15 : 313\n","measurement_10 : 174\n","measurement_16 : 338\n","measurement_14 : 316\n","\n","2389 filled by linear model \n","1584 filled by KNN \n","\n","-------- Product code E ----------\n","\n","filled by linear model :\n","measurement_17 : 429\n","measurement_8 : 177\n","measurement_11 : 244\n","measurement_5 : 116\n","measurement_6 : 127\n","measurement_7 : 185\n","measurement_4 : 105\n","measurement_15 : 315\n","measurement_10 : 193\n","measurement_16 : 316\n","measurement_14 : 297\n","\n","2504 filled by linear model \n","1628 filled by KNN \n","\n","-------- Product code F ----------\n","\n","filled by linear model :\n","measurement_17 : 420\n","measurement_8 : 194\n","measurement_11 : 226\n","measurement_5 : 90\n","measurement_6 : 140\n","measurement_7 : 147\n","measurement_4 : 91\n","measurement_15 : 333\n","measurement_10 : 186\n","measurement_16 : 356\n","measurement_14 : 348\n","\n","2531 filled by linear model \n","1542 filled by KNN \n","\n","-------- Product code G ----------\n","\n","filled by linear model :\n","measurement_17 : 373\n","measurement_8 : 188\n","measurement_11 : 221\n","measurement_5 : 104\n","measurement_6 : 146\n","measurement_7 : 145\n","measurement_4 : 93\n","measurement_15 : 299\n","measurement_10 : 226\n","measurement_16 : 343\n","measurement_14 : 268\n","\n","2406 filled by linear model \n","1518 filled by KNN \n","\n","-------- Product code H ----------\n","\n","filled by linear model :\n","measurement_17 : 361\n","measurement_8 : 147\n","measurement_11 : 205\n","measurement_5 : 112\n","measurement_6 : 121\n","measurement_7 : 161\n","measurement_4 : 75\n","measurement_15 : 299\n","measurement_10 : 217\n","measurement_16 : 340\n","measurement_14 : 283\n","\n","2321 filled by linear model \n","1562 filled by KNN \n","\n","-------- Product code I ----------\n","\n","filled by linear model :\n","measurement_17 : 377\n","measurement_8 : 192\n","measurement_11 : 209\n","measurement_5 : 119\n","measurement_6 : 132\n","measurement_7 : 136\n","measurement_4 : 89\n","measurement_15 : 350\n","measurement_10 : 246\n","measurement_16 : 294\n","measurement_14 : 283\n","\n","2427 filled by linear model \n","1402 filled by KNN \n"]}]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"Nd-yAO5HcdTn","executionInfo":{"status":"ok","timestamp":1673339923823,"user_tz":-480,"elapsed":20,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"dfe0a158-2ac9-424f-a01e-c7b2a96da91a"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id product_code  loading  attribute_0 attribute_1  attribute_2  \\\n","0   0            A    80.10     0.017894  material_8            9   \n","1   1            A    84.89     0.017894  material_8            9   \n","2   2            A    82.43     0.017894  material_8            9   \n","3   3            A   101.07     0.017894  material_8            9   \n","4   4            A   188.06     0.017894  material_8            9   \n","\n","   attribute_3  measurement_0  measurement_1  measurement_2  measurement_3  \\\n","0            5            7.0            8.0            4.0         18.040   \n","1            5           14.0            3.0            3.0         18.213   \n","2            5           12.0            1.0            5.0         18.057   \n","3            5           13.0            2.0            6.0         17.295   \n","4            5            9.0            2.0            8.0         19.346   \n","\n","   measurement_4  measurement_5  measurement_6  measurement_7  measurement_8  \\\n","0         12.518         15.748         19.292         11.739         20.155   \n","1         11.540         17.717         17.893         12.748         17.889   \n","2         11.652         16.738         18.240         12.718         18.288   \n","3         11.188         18.576         18.339         12.583         19.060   \n","4         12.950         16.990         15.746         11.306         18.093   \n","\n","   measurement_9  measurement_10  measurement_11  measurement_12  \\\n","0         10.672          15.859       17.594000          15.193   \n","1         12.448          17.947       17.915000          11.755   \n","2         12.715          15.607       20.188481          13.798   \n","3         12.471          16.346       18.377000          10.020   \n","4         10.337          17.082       19.932000          12.428   \n","\n","   measurement_13  measurement_14  measurement_15  measurement_16  \\\n","0          15.029       15.495862          13.034          14.684   \n","1          14.732       15.425000          14.395          15.631   \n","2          16.711       18.631000          14.094          17.946   \n","3          15.250       15.562000          16.154          17.172   \n","4          16.182       12.760000          13.153          16.412   \n","\n","   measurement_17  failure  m3_missing  m4_missing  m5_missing  area  \\\n","0         764.100      0.0           0           0           0    45   \n","1         682.057      0.0           0           0           0    45   \n","2         663.376      0.0           0           0           0    45   \n","3         826.282      0.0           0           0           0    45   \n","4         579.885      0.0           0           0           0    45   \n","\n","   measurement_avg  measurement_std  measurement_median  measurement_max  \\\n","0        15.360919         2.776473           15.344431        20.155000   \n","1        15.446286         2.540705           15.528000        18.213000   \n","2        16.098820         2.671122           16.724500        20.188481   \n","3        15.599500         2.933476           16.250000        19.060000   \n","4        15.194071         3.027182           15.964000        19.932000   \n","\n","   measurement_min  measurement_skew  \n","0           10.672          0.062682  \n","1           11.540         -0.356926  \n","2           11.652         -0.312815  \n","3           10.020         -0.705741  \n","4           10.337         -0.035574  "],"text/html":["\n","  <div id=\"df-c832035b-39a0-4f87-a7a2-813877a442fb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>measurement_3</th>\n","      <th>measurement_4</th>\n","      <th>measurement_5</th>\n","      <th>measurement_6</th>\n","      <th>measurement_7</th>\n","      <th>measurement_8</th>\n","      <th>measurement_9</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>failure</th>\n","      <th>m3_missing</th>\n","      <th>m4_missing</th>\n","      <th>m5_missing</th>\n","      <th>area</th>\n","      <th>measurement_avg</th>\n","      <th>measurement_std</th>\n","      <th>measurement_median</th>\n","      <th>measurement_max</th>\n","      <th>measurement_min</th>\n","      <th>measurement_skew</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>80.10</td>\n","      <td>0.017894</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>18.040</td>\n","      <td>12.518</td>\n","      <td>15.748</td>\n","      <td>19.292</td>\n","      <td>11.739</td>\n","      <td>20.155</td>\n","      <td>10.672</td>\n","      <td>15.859</td>\n","      <td>17.594000</td>\n","      <td>15.193</td>\n","      <td>15.029</td>\n","      <td>15.495862</td>\n","      <td>13.034</td>\n","      <td>14.684</td>\n","      <td>764.100</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>15.360919</td>\n","      <td>2.776473</td>\n","      <td>15.344431</td>\n","      <td>20.155000</td>\n","      <td>10.672</td>\n","      <td>0.062682</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>84.89</td>\n","      <td>0.017894</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>14.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>18.213</td>\n","      <td>11.540</td>\n","      <td>17.717</td>\n","      <td>17.893</td>\n","      <td>12.748</td>\n","      <td>17.889</td>\n","      <td>12.448</td>\n","      <td>17.947</td>\n","      <td>17.915000</td>\n","      <td>11.755</td>\n","      <td>14.732</td>\n","      <td>15.425000</td>\n","      <td>14.395</td>\n","      <td>15.631</td>\n","      <td>682.057</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>15.446286</td>\n","      <td>2.540705</td>\n","      <td>15.528000</td>\n","      <td>18.213000</td>\n","      <td>11.540</td>\n","      <td>-0.356926</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>82.43</td>\n","      <td>0.017894</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>12.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>18.057</td>\n","      <td>11.652</td>\n","      <td>16.738</td>\n","      <td>18.240</td>\n","      <td>12.718</td>\n","      <td>18.288</td>\n","      <td>12.715</td>\n","      <td>15.607</td>\n","      <td>20.188481</td>\n","      <td>13.798</td>\n","      <td>16.711</td>\n","      <td>18.631000</td>\n","      <td>14.094</td>\n","      <td>17.946</td>\n","      <td>663.376</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>16.098820</td>\n","      <td>2.671122</td>\n","      <td>16.724500</td>\n","      <td>20.188481</td>\n","      <td>11.652</td>\n","      <td>-0.312815</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>101.07</td>\n","      <td>0.017894</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>13.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>17.295</td>\n","      <td>11.188</td>\n","      <td>18.576</td>\n","      <td>18.339</td>\n","      <td>12.583</td>\n","      <td>19.060</td>\n","      <td>12.471</td>\n","      <td>16.346</td>\n","      <td>18.377000</td>\n","      <td>10.020</td>\n","      <td>15.250</td>\n","      <td>15.562000</td>\n","      <td>16.154</td>\n","      <td>17.172</td>\n","      <td>826.282</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>15.599500</td>\n","      <td>2.933476</td>\n","      <td>16.250000</td>\n","      <td>19.060000</td>\n","      <td>10.020</td>\n","      <td>-0.705741</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>188.06</td>\n","      <td>0.017894</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>9.0</td>\n","      <td>2.0</td>\n","      <td>8.0</td>\n","      <td>19.346</td>\n","      <td>12.950</td>\n","      <td>16.990</td>\n","      <td>15.746</td>\n","      <td>11.306</td>\n","      <td>18.093</td>\n","      <td>10.337</td>\n","      <td>17.082</td>\n","      <td>19.932000</td>\n","      <td>12.428</td>\n","      <td>16.182</td>\n","      <td>12.760000</td>\n","      <td>13.153</td>\n","      <td>16.412</td>\n","      <td>579.885</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>15.194071</td>\n","      <td>3.027182</td>\n","      <td>15.964000</td>\n","      <td>19.932000</td>\n","      <td>10.337</td>\n","      <td>-0.035574</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c832035b-39a0-4f87-a7a2-813877a442fb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c832035b-39a0-4f87-a7a2-813877a442fb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c832035b-39a0-4f87-a7a2-813877a442fb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["df_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"K-Vv5vzm8-dm","executionInfo":{"status":"ok","timestamp":1673339923823,"user_tz":-480,"elapsed":19,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"e751c52f-a0e6-4e57-d1c5-33184772f6e6"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id product_code  loading  attribute_0 attribute_1  attribute_2  \\\n","0  26570            F   119.57     -0.07464  material_6            6   \n","1  26571            F   113.51     -0.07464  material_6            6   \n","2  26572            F   112.16     -0.07464  material_6            6   \n","3  26573            F   112.72     -0.07464  material_6            6   \n","4  26574            F   208.00     -0.07464  material_6            6   \n","\n","   attribute_3  measurement_0  measurement_1  measurement_2  measurement_3  \\\n","0            4            6.0            9.0            6.0         19.305   \n","1            4           11.0            8.0            0.0         17.883   \n","2            4            8.0           12.0            4.0         18.475   \n","3            4            8.0           11.0           10.0         16.518   \n","4            4           14.0           16.0            8.0         17.808   \n","\n","   measurement_4  measurement_5  measurement_6  measurement_7  measurement_8  \\\n","0         10.178         17.534         18.168         11.598         18.654   \n","1         11.927         17.228         16.033         11.179         19.368   \n","2         10.481         16.619         18.189         12.126         17.774   \n","3         10.888         15.293         18.592         11.304         18.948   \n","4         12.693         17.678         15.814         13.431         19.141   \n","\n","   measurement_9  measurement_10  measurement_11  measurement_12  \\\n","0         10.802          15.909       18.070000          13.772   \n","1         12.032          13.998       17.958412          12.473   \n","2         11.743          17.046       18.086000          10.907   \n","3         11.790          18.165       16.163000          10.933   \n","4         12.370          14.578       17.849000          11.941   \n","\n","   measurement_13  measurement_14  measurement_15  measurement_16  \\\n","0          13.659          16.825          13.742          17.710   \n","1          17.468          16.708          14.776          14.102   \n","2          13.363          15.737          17.065          16.021   \n","3          15.501          15.667          12.620          16.111   \n","4          16.070          16.183          13.324          17.150   \n","\n","   measurement_17  failure  m3_missing  m4_missing  m5_missing  area  \\\n","0         634.612      NaN           0           0           0    24   \n","1         537.037      NaN           0           0           0    24   \n","2         658.995      NaN           0           0           0    24   \n","3         594.301      NaN           0           0           0    24   \n","4         801.044      NaN           0           0           0    24   \n","\n","   measurement_avg  measurement_std  measurement_median  measurement_max  \\\n","0        15.423286         3.089647             16.3670           19.305   \n","1        15.223815         2.654171             15.4045           19.368   \n","2        15.259429         2.907555             16.3200           18.475   \n","3        14.892357         2.870206             15.5840           18.948   \n","4        15.430714         2.363162             15.9420           19.141   \n","\n","   measurement_min  measurement_skew  \n","0           10.178         -0.480986  \n","1           11.179         -0.120501  \n","2           10.481         -0.588183  \n","3           10.888         -0.200273  \n","4           11.941         -0.094032  "],"text/html":["\n","  <div id=\"df-bc4a4e08-a3c3-4b68-821b-b6482b9d2608\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>measurement_3</th>\n","      <th>measurement_4</th>\n","      <th>measurement_5</th>\n","      <th>measurement_6</th>\n","      <th>measurement_7</th>\n","      <th>measurement_8</th>\n","      <th>measurement_9</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>failure</th>\n","      <th>m3_missing</th>\n","      <th>m4_missing</th>\n","      <th>m5_missing</th>\n","      <th>area</th>\n","      <th>measurement_avg</th>\n","      <th>measurement_std</th>\n","      <th>measurement_median</th>\n","      <th>measurement_max</th>\n","      <th>measurement_min</th>\n","      <th>measurement_skew</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>26570</td>\n","      <td>F</td>\n","      <td>119.57</td>\n","      <td>-0.07464</td>\n","      <td>material_6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>6.0</td>\n","      <td>9.0</td>\n","      <td>6.0</td>\n","      <td>19.305</td>\n","      <td>10.178</td>\n","      <td>17.534</td>\n","      <td>18.168</td>\n","      <td>11.598</td>\n","      <td>18.654</td>\n","      <td>10.802</td>\n","      <td>15.909</td>\n","      <td>18.070000</td>\n","      <td>13.772</td>\n","      <td>13.659</td>\n","      <td>16.825</td>\n","      <td>13.742</td>\n","      <td>17.710</td>\n","      <td>634.612</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>15.423286</td>\n","      <td>3.089647</td>\n","      <td>16.3670</td>\n","      <td>19.305</td>\n","      <td>10.178</td>\n","      <td>-0.480986</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>26571</td>\n","      <td>F</td>\n","      <td>113.51</td>\n","      <td>-0.07464</td>\n","      <td>material_6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>11.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>17.883</td>\n","      <td>11.927</td>\n","      <td>17.228</td>\n","      <td>16.033</td>\n","      <td>11.179</td>\n","      <td>19.368</td>\n","      <td>12.032</td>\n","      <td>13.998</td>\n","      <td>17.958412</td>\n","      <td>12.473</td>\n","      <td>17.468</td>\n","      <td>16.708</td>\n","      <td>14.776</td>\n","      <td>14.102</td>\n","      <td>537.037</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>15.223815</td>\n","      <td>2.654171</td>\n","      <td>15.4045</td>\n","      <td>19.368</td>\n","      <td>11.179</td>\n","      <td>-0.120501</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26572</td>\n","      <td>F</td>\n","      <td>112.16</td>\n","      <td>-0.07464</td>\n","      <td>material_6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>8.0</td>\n","      <td>12.0</td>\n","      <td>4.0</td>\n","      <td>18.475</td>\n","      <td>10.481</td>\n","      <td>16.619</td>\n","      <td>18.189</td>\n","      <td>12.126</td>\n","      <td>17.774</td>\n","      <td>11.743</td>\n","      <td>17.046</td>\n","      <td>18.086000</td>\n","      <td>10.907</td>\n","      <td>13.363</td>\n","      <td>15.737</td>\n","      <td>17.065</td>\n","      <td>16.021</td>\n","      <td>658.995</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>15.259429</td>\n","      <td>2.907555</td>\n","      <td>16.3200</td>\n","      <td>18.475</td>\n","      <td>10.481</td>\n","      <td>-0.588183</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26573</td>\n","      <td>F</td>\n","      <td>112.72</td>\n","      <td>-0.07464</td>\n","      <td>material_6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>8.0</td>\n","      <td>11.0</td>\n","      <td>10.0</td>\n","      <td>16.518</td>\n","      <td>10.888</td>\n","      <td>15.293</td>\n","      <td>18.592</td>\n","      <td>11.304</td>\n","      <td>18.948</td>\n","      <td>11.790</td>\n","      <td>18.165</td>\n","      <td>16.163000</td>\n","      <td>10.933</td>\n","      <td>15.501</td>\n","      <td>15.667</td>\n","      <td>12.620</td>\n","      <td>16.111</td>\n","      <td>594.301</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>14.892357</td>\n","      <td>2.870206</td>\n","      <td>15.5840</td>\n","      <td>18.948</td>\n","      <td>10.888</td>\n","      <td>-0.200273</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26574</td>\n","      <td>F</td>\n","      <td>208.00</td>\n","      <td>-0.07464</td>\n","      <td>material_6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>14.0</td>\n","      <td>16.0</td>\n","      <td>8.0</td>\n","      <td>17.808</td>\n","      <td>12.693</td>\n","      <td>17.678</td>\n","      <td>15.814</td>\n","      <td>13.431</td>\n","      <td>19.141</td>\n","      <td>12.370</td>\n","      <td>14.578</td>\n","      <td>17.849000</td>\n","      <td>11.941</td>\n","      <td>16.070</td>\n","      <td>16.183</td>\n","      <td>13.324</td>\n","      <td>17.150</td>\n","      <td>801.044</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>15.430714</td>\n","      <td>2.363162</td>\n","      <td>15.9420</td>\n","      <td>19.141</td>\n","      <td>11.941</td>\n","      <td>-0.094032</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc4a4e08-a3c3-4b68-821b-b6482b9d2608')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bc4a4e08-a3c3-4b68-821b-b6482b9d2608 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bc4a4e08-a3c3-4b68-821b-b6482b9d2608');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["# features = ['loading', 'attribute_0', 'measurement_17', 'measurement_0', \n","#             'measurement_1', 'measurement_2','measurement_3','measurement_4',\n","#             'measurement_5', 'measurement_6','measurement_7','measurement_8',\n","#             'measurement_9','measurement_10','measurement_11', 'measurement_12',\n","#             'measurement_13','measurement_14','measurement_15','measurement_16', 'measurement_17',\n","#             'area', 'm3_missing', 'm5_missing', 'measurement_avg']\n","# 17 6 4 2 5miss 4miss 9 7 \n","# 17 0 1 2 3miss 5miss avg std median min skew\n","features = ['loading', 'attribute_0', 'measurement_17',\n","            'measurement_0', 'measurement_1', 'measurement_2',\n","            'area', 'm3_missing',\n","            'm4_missing', 'm5_missing', 'measurement_avg',\n","            'measurement_std', 'measurement_median', 'measurement_min',\n","            'measurement_skew']\n","features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K25W8jGAcrhv","executionInfo":{"status":"ok","timestamp":1673339923824,"user_tz":-480,"elapsed":19,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"41dcb19b-e2ea-4ea4-fb4a-b3b887a25dd5"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['loading',\n"," 'attribute_0',\n"," 'measurement_17',\n"," 'measurement_0',\n"," 'measurement_1',\n"," 'measurement_2',\n"," 'area',\n"," 'm3_missing',\n"," 'm4_missing',\n"," 'm5_missing',\n"," 'measurement_avg',\n"," 'measurement_std',\n"," 'measurement_median',\n"," 'measurement_min',\n"," 'measurement_skew']"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["tf.keras.utils.set_random_seed(42)\n","test_predictions = np.zeros((df_test.shape[0], 1))\n","\n","models = []\n","auc_score = []\n","targets = []\n","for fold in folds_dict.keys():\n","    \n","    print(f'########################## {fold} ##########################')\n","    \n","    x_train = df_train[df_train['product_code'].isin(folds_dict[fold][0])][features].values\n","    y_train = df_train[df_train['product_code'].isin(folds_dict[fold][0])]['failure'].values\n","    x_valid = df_train[df_train['product_code'].isin(folds_dict[fold][1])][features].values\n","    y_valid = df_train[df_train['product_code'].isin(folds_dict[fold][1])]['failure'].values\n","    trn_index = df_train[df_train['product_code'].isin(folds_dict[fold][0])][features].index\n","    vld_index = df_train[df_train['product_code'].isin(folds_dict[fold][1])][features].index\n","    \n","    print(f\"x_train len:{len(x_train)} shape:{x_train.shape}\")\n","    total_col = x_train.shape[1]\n","    model = Sequential([\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(total_col*20, activation=\"relu\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.1),\n","        tf.keras.layers.Dense(total_col*5, activation=\"relu\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(total_col, activation=\"relu\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.1),\n","        tf.keras.layers.Dense(total_col-5, activation=\"relu\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(1, activation=\"sigmoid\") \n","    ])\n","    es_callbacks = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", \n","                                                    patience = 7, restore_best_weights = True)\n","    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\",\n","                                                    factor=0.9, patience= 5, verbose=0, mode=\"max\",\n","                                                    min_delta=0.0001, cooldown=0, min_lr=0)\n","    \n","    model.compile(optimizer = tfa.optimizers.AdamW(learning_rate = 1e-3, weight_decay = 1e-3 ), \n","                  loss = \"BinaryCrossentropy\", metrics=[\"AUC\"])\n","    model.fit(x_train,\n","              y_train,\n","              batch_size = 64,\n","              epochs = 200,\n","              callbacks = [es_callbacks, lr_scheduler],\n","              validation_data = (x_valid, y_valid)\n","              \n","             )\n","    predictions = model.predict(x_valid).reshape(-1, 1)\n","    test_pred = model.predict(df_test[features].values).reshape(-1, 1)\n","    models.append(model)\n","    \n","    score = roc_auc_score(y_valid, predictions)\n","    auc_score.append(score)\n","    test_predictions += test_pred * score\n","    \n","    print('\\n')\n","    print(f'AUC score {fold} : {score}')\n","    print('\\n')\n","\n","test_predictions /= np.sum(np.array(auc_score))\n","models.append(auc_score)\n","with open('0711257_model.pkl', 'wb') as fp:\n","    pickle.dump(models, fp)\n","    print('Done saving models into a binary file')\n","\n","print('\\n')\n","print(f'CV AUC score: {np.mean(np.array(auc_score))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4hf8ijmcy0i","executionInfo":{"status":"ok","timestamp":1673342779291,"user_tz":-480,"elapsed":670465,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}},"outputId":"b9e508ff-ec94-4091-9baf-dbca8432c40d"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["########################## Fold 1 ##########################\n","x_train len:16220 shape:(16220, 15)\n","Epoch 1/200\n","254/254 [==============================] - 5s 13ms/step - loss: 0.6477 - auc: 0.5248 - val_loss: 0.5604 - val_auc: 0.5404 - lr: 0.0010\n","Epoch 2/200\n","254/254 [==============================] - 3s 13ms/step - loss: 0.5485 - auc: 0.5226 - val_loss: 0.5296 - val_auc: 0.5600 - lr: 0.0010\n","Epoch 3/200\n","254/254 [==============================] - 2s 8ms/step - loss: 0.5265 - auc: 0.5476 - val_loss: 0.5210 - val_auc: 0.5662 - lr: 0.0010\n","Epoch 4/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5186 - auc: 0.5591 - val_loss: 0.5178 - val_auc: 0.5866 - lr: 0.0010\n","Epoch 5/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5178 - auc: 0.5508 - val_loss: 0.5197 - val_auc: 0.5781 - lr: 0.0010\n","Epoch 6/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5154 - auc: 0.5664 - val_loss: 0.5154 - val_auc: 0.5851 - lr: 0.0010\n","Epoch 7/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5148 - auc: 0.5613 - val_loss: 0.5164 - val_auc: 0.5840 - lr: 0.0010\n","Epoch 8/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5147 - auc: 0.5635 - val_loss: 0.5200 - val_auc: 0.5865 - lr: 0.0010\n","Epoch 9/200\n","254/254 [==============================] - 3s 12ms/step - loss: 0.5154 - auc: 0.5565 - val_loss: 0.5125 - val_auc: 0.5919 - lr: 0.0010\n","Epoch 10/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5161 - auc: 0.5531 - val_loss: 0.5115 - val_auc: 0.5916 - lr: 0.0010\n","Epoch 11/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5134 - auc: 0.5689 - val_loss: 0.5109 - val_auc: 0.5921 - lr: 0.0010\n","Epoch 12/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5149 - auc: 0.5593 - val_loss: 0.5102 - val_auc: 0.5923 - lr: 0.0010\n","Epoch 13/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5147 - auc: 0.5566 - val_loss: 0.5115 - val_auc: 0.5932 - lr: 0.0010\n","Epoch 14/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5142 - auc: 0.5584 - val_loss: 0.5113 - val_auc: 0.5920 - lr: 0.0010\n","Epoch 15/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5139 - auc: 0.5625 - val_loss: 0.5262 - val_auc: 0.5904 - lr: 0.0010\n","Epoch 16/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5133 - auc: 0.5682 - val_loss: 0.5129 - val_auc: 0.5844 - lr: 0.0010\n","Epoch 17/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5131 - auc: 0.5660 - val_loss: 0.5119 - val_auc: 0.5918 - lr: 0.0010\n","Epoch 18/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5143 - auc: 0.5565 - val_loss: 0.5121 - val_auc: 0.5926 - lr: 0.0010\n","Epoch 19/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5144 - auc: 0.5568 - val_loss: 0.5145 - val_auc: 0.5922 - lr: 9.0000e-04\n","Epoch 20/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5133 - auc: 0.5658 - val_loss: 0.5123 - val_auc: 0.5922 - lr: 9.0000e-04\n","324/324 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 1 : 0.5931926557163806\n","\n","\n","########################## Fold 2 ##########################\n","x_train len:15705 shape:(15705, 15)\n","Epoch 1/200\n","246/246 [==============================] - 5s 11ms/step - loss: 0.6558 - auc: 0.5084 - val_loss: 0.5672 - val_auc: 0.5027 - lr: 0.0010\n","Epoch 2/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5484 - auc: 0.5251 - val_loss: 0.5350 - val_auc: 0.5562 - lr: 0.0010\n","Epoch 3/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5253 - auc: 0.5377 - val_loss: 0.5261 - val_auc: 0.5787 - lr: 0.0010\n","Epoch 4/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5149 - auc: 0.5583 - val_loss: 0.5252 - val_auc: 0.5851 - lr: 0.0010\n","Epoch 5/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5122 - auc: 0.5654 - val_loss: 0.5224 - val_auc: 0.5798 - lr: 0.0010\n","Epoch 6/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5105 - auc: 0.5686 - val_loss: 0.5211 - val_auc: 0.5859 - lr: 0.0010\n","Epoch 7/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5102 - auc: 0.5602 - val_loss: 0.5212 - val_auc: 0.5811 - lr: 0.0010\n","Epoch 8/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5103 - auc: 0.5609 - val_loss: 0.5204 - val_auc: 0.5863 - lr: 0.0010\n","Epoch 9/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5097 - auc: 0.5620 - val_loss: 0.5195 - val_auc: 0.5884 - lr: 0.0010\n","Epoch 10/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5095 - auc: 0.5656 - val_loss: 0.5194 - val_auc: 0.5868 - lr: 0.0010\n","Epoch 11/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5081 - auc: 0.5698 - val_loss: 0.5185 - val_auc: 0.5888 - lr: 0.0010\n","Epoch 12/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5095 - auc: 0.5629 - val_loss: 0.5207 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 13/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5098 - auc: 0.5600 - val_loss: 0.5191 - val_auc: 0.5874 - lr: 0.0010\n","Epoch 14/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5096 - auc: 0.5595 - val_loss: 0.5187 - val_auc: 0.5870 - lr: 0.0010\n","Epoch 15/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5083 - auc: 0.5687 - val_loss: 0.5178 - val_auc: 0.5882 - lr: 0.0010\n","Epoch 16/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5083 - auc: 0.5686 - val_loss: 0.5257 - val_auc: 0.5877 - lr: 0.0010\n","Epoch 17/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5087 - auc: 0.5620 - val_loss: 0.5203 - val_auc: 0.5886 - lr: 9.0000e-04\n","Epoch 18/200\n","246/246 [==============================] - 2s 8ms/step - loss: 0.5086 - auc: 0.5658 - val_loss: 0.5189 - val_auc: 0.5891 - lr: 9.0000e-04\n","Epoch 19/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5085 - auc: 0.5673 - val_loss: 0.5213 - val_auc: 0.5887 - lr: 9.0000e-04\n","Epoch 20/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5078 - auc: 0.5691 - val_loss: 0.5210 - val_auc: 0.5887 - lr: 9.0000e-04\n","Epoch 21/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5081 - auc: 0.5707 - val_loss: 0.5199 - val_auc: 0.5897 - lr: 9.0000e-04\n","Epoch 22/200\n","246/246 [==============================] - 3s 12ms/step - loss: 0.5096 - auc: 0.5563 - val_loss: 0.5199 - val_auc: 0.5871 - lr: 9.0000e-04\n","Epoch 23/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5089 - auc: 0.5634 - val_loss: 0.5175 - val_auc: 0.5885 - lr: 9.0000e-04\n","Epoch 24/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5097 - auc: 0.5561 - val_loss: 0.5195 - val_auc: 0.5871 - lr: 9.0000e-04\n","Epoch 25/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5089 - auc: 0.5622 - val_loss: 0.5229 - val_auc: 0.5879 - lr: 9.0000e-04\n","Epoch 26/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5083 - auc: 0.5674 - val_loss: 0.5180 - val_auc: 0.5897 - lr: 9.0000e-04\n","Epoch 27/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5082 - auc: 0.5687 - val_loss: 0.5214 - val_auc: 0.5883 - lr: 8.1000e-04\n","Epoch 28/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5108 - auc: 0.5534 - val_loss: 0.5186 - val_auc: 0.5878 - lr: 8.1000e-04\n","Epoch 29/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5089 - auc: 0.5621 - val_loss: 0.5182 - val_auc: 0.5884 - lr: 8.1000e-04\n","Epoch 30/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5093 - auc: 0.5654 - val_loss: 0.5181 - val_auc: 0.5872 - lr: 8.1000e-04\n","Epoch 31/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5078 - auc: 0.5709 - val_loss: 0.5221 - val_auc: 0.5875 - lr: 8.1000e-04\n","Epoch 32/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5098 - auc: 0.5631 - val_loss: 0.5234 - val_auc: 0.5888 - lr: 7.2900e-04\n","Epoch 33/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5096 - auc: 0.5668 - val_loss: 0.5206 - val_auc: 0.5874 - lr: 7.2900e-04\n","340/340 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 2 : 0.589904550154412\n","\n","\n","########################## Fold 3 ##########################\n","x_train len:16358 shape:(16358, 15)\n","Epoch 1/200\n","256/256 [==============================] - 4s 11ms/step - loss: 0.6456 - auc: 0.5263 - val_loss: 0.5835 - val_auc: 0.4849 - lr: 0.0010\n","Epoch 2/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5419 - auc: 0.5278 - val_loss: 0.5408 - val_auc: 0.5354 - lr: 0.0010\n","Epoch 3/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5185 - auc: 0.5415 - val_loss: 0.5300 - val_auc: 0.5763 - lr: 0.0010\n","Epoch 4/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5119 - auc: 0.5576 - val_loss: 0.5294 - val_auc: 0.5760 - lr: 0.0010\n","Epoch 5/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5102 - auc: 0.5525 - val_loss: 0.5284 - val_auc: 0.5841 - lr: 0.0010\n","Epoch 6/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5093 - auc: 0.5553 - val_loss: 0.5257 - val_auc: 0.5903 - lr: 0.0010\n","Epoch 7/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5086 - auc: 0.5570 - val_loss: 0.5236 - val_auc: 0.5927 - lr: 0.0010\n","Epoch 8/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5082 - auc: 0.5588 - val_loss: 0.5240 - val_auc: 0.5937 - lr: 0.0010\n","Epoch 9/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5076 - auc: 0.5574 - val_loss: 0.5257 - val_auc: 0.5947 - lr: 0.0010\n","Epoch 10/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5070 - auc: 0.5649 - val_loss: 0.5235 - val_auc: 0.5941 - lr: 0.0010\n","Epoch 11/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5071 - auc: 0.5615 - val_loss: 0.5214 - val_auc: 0.5933 - lr: 0.0010\n","Epoch 12/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5075 - auc: 0.5575 - val_loss: 0.5238 - val_auc: 0.5933 - lr: 0.0010\n","Epoch 13/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5078 - auc: 0.5558 - val_loss: 0.5223 - val_auc: 0.5933 - lr: 0.0010\n","Epoch 14/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5076 - auc: 0.5544 - val_loss: 0.5224 - val_auc: 0.5926 - lr: 0.0010\n","Epoch 15/200\n","256/256 [==============================] - 2s 8ms/step - loss: 0.5078 - auc: 0.5565 - val_loss: 0.5234 - val_auc: 0.5945 - lr: 9.0000e-04\n","Epoch 16/200\n","256/256 [==============================] - 2s 9ms/step - loss: 0.5054 - auc: 0.5716 - val_loss: 0.5236 - val_auc: 0.5934 - lr: 9.0000e-04\n","320/320 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 3 : 0.5943541345294733\n","\n","\n","########################## Fold 4 ##########################\n","x_train len:16127 shape:(16127, 15)\n","Epoch 1/200\n","252/252 [==============================] - 4s 10ms/step - loss: 0.6501 - auc: 0.5262 - val_loss: 0.5598 - val_auc: 0.5302 - lr: 0.0010\n","Epoch 2/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5501 - auc: 0.5224 - val_loss: 0.5292 - val_auc: 0.5407 - lr: 0.0010\n","Epoch 3/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5245 - auc: 0.5486 - val_loss: 0.5234 - val_auc: 0.5648 - lr: 0.0010\n","Epoch 4/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5169 - auc: 0.5587 - val_loss: 0.5201 - val_auc: 0.5764 - lr: 0.0010\n","Epoch 5/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5150 - auc: 0.5589 - val_loss: 0.5207 - val_auc: 0.5776 - lr: 0.0010\n","Epoch 6/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5128 - auc: 0.5657 - val_loss: 0.5209 - val_auc: 0.5740 - lr: 0.0010\n","Epoch 7/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5131 - auc: 0.5555 - val_loss: 0.5197 - val_auc: 0.5804 - lr: 0.0010\n","Epoch 8/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5105 - auc: 0.5708 - val_loss: 0.5211 - val_auc: 0.5838 - lr: 0.0010\n","Epoch 9/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5123 - auc: 0.5595 - val_loss: 0.5168 - val_auc: 0.5868 - lr: 0.0010\n","Epoch 10/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5104 - auc: 0.5696 - val_loss: 0.5173 - val_auc: 0.5881 - lr: 0.0010\n","Epoch 11/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5117 - auc: 0.5643 - val_loss: 0.5160 - val_auc: 0.5865 - lr: 0.0010\n","Epoch 12/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5097 - auc: 0.5686 - val_loss: 0.5189 - val_auc: 0.5874 - lr: 0.0010\n","Epoch 13/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5103 - auc: 0.5663 - val_loss: 0.5168 - val_auc: 0.5867 - lr: 0.0010\n","Epoch 14/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5104 - auc: 0.5682 - val_loss: 0.5189 - val_auc: 0.5886 - lr: 0.0010\n","Epoch 15/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5116 - auc: 0.5599 - val_loss: 0.5176 - val_auc: 0.5876 - lr: 0.0010\n","Epoch 16/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5117 - auc: 0.5566 - val_loss: 0.5161 - val_auc: 0.5887 - lr: 0.0010\n","Epoch 17/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5103 - auc: 0.5683 - val_loss: 0.5155 - val_auc: 0.5885 - lr: 0.0010\n","Epoch 18/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5101 - auc: 0.5671 - val_loss: 0.5236 - val_auc: 0.5890 - lr: 0.0010\n","Epoch 19/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5108 - auc: 0.5664 - val_loss: 0.5170 - val_auc: 0.5837 - lr: 0.0010\n","Epoch 20/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5103 - auc: 0.5663 - val_loss: 0.5157 - val_auc: 0.5873 - lr: 0.0010\n","Epoch 21/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5117 - auc: 0.5576 - val_loss: 0.5204 - val_auc: 0.5880 - lr: 0.0010\n","Epoch 22/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5115 - auc: 0.5582 - val_loss: 0.5186 - val_auc: 0.5860 - lr: 0.0010\n","Epoch 23/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5097 - auc: 0.5699 - val_loss: 0.5163 - val_auc: 0.5885 - lr: 0.0010\n","Epoch 24/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5099 - auc: 0.5683 - val_loss: 0.5162 - val_auc: 0.5869 - lr: 9.0000e-04\n","Epoch 25/200\n","252/252 [==============================] - 2s 8ms/step - loss: 0.5087 - auc: 0.5760 - val_loss: 0.5156 - val_auc: 0.5878 - lr: 9.0000e-04\n","327/327 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 4 : 0.5887267946037315\n","\n","\n","########################## Fold 5 ##########################\n","x_train len:15555 shape:(15555, 15)\n","Epoch 1/200\n","244/244 [==============================] - 5s 11ms/step - loss: 0.6674 - auc: 0.5230 - val_loss: 0.6080 - val_auc: 0.5026 - lr: 0.0010\n","Epoch 2/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5592 - auc: 0.5462 - val_loss: 0.5425 - val_auc: 0.5438 - lr: 0.0010\n","Epoch 3/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5329 - auc: 0.5475 - val_loss: 0.5241 - val_auc: 0.5648 - lr: 0.0010\n","Epoch 4/200\n","244/244 [==============================] - 4s 16ms/step - loss: 0.5267 - auc: 0.5556 - val_loss: 0.5156 - val_auc: 0.5804 - lr: 0.0010\n","Epoch 5/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5223 - auc: 0.5629 - val_loss: 0.5149 - val_auc: 0.5837 - lr: 0.0010\n","Epoch 6/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5230 - auc: 0.5605 - val_loss: 0.5089 - val_auc: 0.5849 - lr: 0.0010\n","Epoch 7/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5198 - auc: 0.5751 - val_loss: 0.5060 - val_auc: 0.5857 - lr: 0.0010\n","Epoch 8/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5213 - auc: 0.5627 - val_loss: 0.5067 - val_auc: 0.5841 - lr: 0.0010\n","Epoch 9/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5200 - auc: 0.5676 - val_loss: 0.5099 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 10/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5206 - auc: 0.5659 - val_loss: 0.5067 - val_auc: 0.5906 - lr: 0.0010\n","Epoch 11/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5202 - auc: 0.5647 - val_loss: 0.5065 - val_auc: 0.5898 - lr: 0.0010\n","Epoch 12/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5215 - auc: 0.5591 - val_loss: 0.5036 - val_auc: 0.5880 - lr: 0.0010\n","Epoch 13/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5202 - auc: 0.5638 - val_loss: 0.5111 - val_auc: 0.5878 - lr: 0.0010\n","Epoch 14/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5201 - auc: 0.5677 - val_loss: 0.5058 - val_auc: 0.5862 - lr: 0.0010\n","Epoch 15/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5192 - auc: 0.5705 - val_loss: 0.5096 - val_auc: 0.5876 - lr: 0.0010\n","Epoch 16/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5201 - auc: 0.5663 - val_loss: 0.5062 - val_auc: 0.5884 - lr: 9.0000e-04\n","Epoch 17/200\n","244/244 [==============================] - 2s 9ms/step - loss: 0.5186 - auc: 0.5748 - val_loss: 0.5079 - val_auc: 0.5878 - lr: 9.0000e-04\n","345/345 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 5 : 0.5905631698517768\n","\n","\n","########################## Fold 6 ##########################\n","x_train len:16208 shape:(16208, 15)\n","Epoch 1/200\n","254/254 [==============================] - 4s 11ms/step - loss: 0.6600 - auc: 0.5174 - val_loss: 0.5895 - val_auc: 0.5426 - lr: 0.0010\n","Epoch 2/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5551 - auc: 0.5216 - val_loss: 0.5353 - val_auc: 0.5556 - lr: 0.0010\n","Epoch 3/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5289 - auc: 0.5544 - val_loss: 0.5201 - val_auc: 0.5750 - lr: 0.0010\n","Epoch 4/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5230 - auc: 0.5479 - val_loss: 0.5171 - val_auc: 0.5812 - lr: 0.0010\n","Epoch 5/200\n","254/254 [==============================] - 2s 8ms/step - loss: 0.5191 - auc: 0.5669 - val_loss: 0.5131 - val_auc: 0.5812 - lr: 0.0010\n","Epoch 6/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5222 - auc: 0.5422 - val_loss: 0.5116 - val_auc: 0.5881 - lr: 0.0010\n","Epoch 7/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5194 - auc: 0.5568 - val_loss: 0.5093 - val_auc: 0.5937 - lr: 0.0010\n","Epoch 8/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5199 - auc: 0.5533 - val_loss: 0.5070 - val_auc: 0.5934 - lr: 0.0010\n","Epoch 9/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5187 - auc: 0.5622 - val_loss: 0.5090 - val_auc: 0.5935 - lr: 0.0010\n","Epoch 10/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5176 - auc: 0.5672 - val_loss: 0.5076 - val_auc: 0.5930 - lr: 0.0010\n","Epoch 11/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5172 - auc: 0.5681 - val_loss: 0.5121 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 12/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5182 - auc: 0.5593 - val_loss: 0.5058 - val_auc: 0.5941 - lr: 0.0010\n","Epoch 13/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5174 - auc: 0.5687 - val_loss: 0.5110 - val_auc: 0.5928 - lr: 0.0010\n","Epoch 14/200\n","254/254 [==============================] - 2s 8ms/step - loss: 0.5183 - auc: 0.5577 - val_loss: 0.5076 - val_auc: 0.5938 - lr: 0.0010\n","Epoch 15/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5177 - auc: 0.5616 - val_loss: 0.5164 - val_auc: 0.5903 - lr: 0.0010\n","Epoch 16/200\n","254/254 [==============================] - 2s 9ms/step - loss: 0.5184 - auc: 0.5567 - val_loss: 0.5061 - val_auc: 0.5903 - lr: 0.0010\n","Epoch 17/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5174 - auc: 0.5648 - val_loss: 0.5072 - val_auc: 0.5929 - lr: 0.0010\n","Epoch 18/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5172 - auc: 0.5659 - val_loss: 0.5090 - val_auc: 0.5906 - lr: 9.0000e-04\n","Epoch 19/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5167 - auc: 0.5690 - val_loss: 0.5105 - val_auc: 0.5929 - lr: 9.0000e-04\n","324/324 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 6 : 0.5940301081053536\n","\n","\n","########################## Fold 7 ##########################\n","x_train len:15977 shape:(15977, 15)\n","Epoch 1/200\n","250/250 [==============================] - 4s 10ms/step - loss: 0.6611 - auc: 0.5330 - val_loss: 0.5448 - val_auc: 0.4932 - lr: 0.0010\n","Epoch 2/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5562 - auc: 0.5186 - val_loss: 0.5146 - val_auc: 0.5602 - lr: 0.0010\n","Epoch 3/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5340 - auc: 0.5397 - val_loss: 0.5109 - val_auc: 0.5662 - lr: 0.0010\n","Epoch 4/200\n","250/250 [==============================] - 2s 10ms/step - loss: 0.5277 - auc: 0.5516 - val_loss: 0.5082 - val_auc: 0.5793 - lr: 0.0010\n","Epoch 5/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5256 - auc: 0.5593 - val_loss: 0.5067 - val_auc: 0.5846 - lr: 0.0010\n","Epoch 6/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5223 - auc: 0.5716 - val_loss: 0.5070 - val_auc: 0.5705 - lr: 0.0010\n","Epoch 7/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5237 - auc: 0.5628 - val_loss: 0.5099 - val_auc: 0.5796 - lr: 0.0010\n","Epoch 8/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5231 - auc: 0.5604 - val_loss: 0.5080 - val_auc: 0.5856 - lr: 0.0010\n","Epoch 9/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5222 - auc: 0.5658 - val_loss: 0.5005 - val_auc: 0.5849 - lr: 0.0010\n","Epoch 10/200\n","250/250 [==============================] - 2s 10ms/step - loss: 0.5230 - auc: 0.5586 - val_loss: 0.5034 - val_auc: 0.5868 - lr: 0.0010\n","Epoch 11/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5220 - auc: 0.5680 - val_loss: 0.5004 - val_auc: 0.5871 - lr: 0.0010\n","Epoch 12/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5219 - auc: 0.5682 - val_loss: 0.4988 - val_auc: 0.5858 - lr: 0.0010\n","Epoch 13/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5213 - auc: 0.5692 - val_loss: 0.5020 - val_auc: 0.5860 - lr: 0.0010\n","Epoch 14/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5213 - auc: 0.5679 - val_loss: 0.5010 - val_auc: 0.5869 - lr: 0.0010\n","Epoch 15/200\n","250/250 [==============================] - 2s 8ms/step - loss: 0.5226 - auc: 0.5576 - val_loss: 0.5040 - val_auc: 0.5864 - lr: 0.0010\n","Epoch 16/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5220 - auc: 0.5616 - val_loss: 0.5106 - val_auc: 0.5838 - lr: 0.0010\n","Epoch 17/200\n","250/250 [==============================] - 2s 9ms/step - loss: 0.5221 - auc: 0.5644 - val_loss: 0.5010 - val_auc: 0.5839 - lr: 9.0000e-04\n","Epoch 18/200\n","250/250 [==============================] - 2s 10ms/step - loss: 0.5218 - auc: 0.5647 - val_loss: 0.5046 - val_auc: 0.5855 - lr: 9.0000e-04\n","332/332 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 7 : 0.5873384651642913\n","\n","\n","########################## Fold 8 ##########################\n","x_train len:15693 shape:(15693, 15)\n","Epoch 1/200\n","246/246 [==============================] - 4s 11ms/step - loss: 0.6556 - auc: 0.5254 - val_loss: 0.5474 - val_auc: 0.5153 - lr: 0.0010\n","Epoch 2/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5462 - auc: 0.5323 - val_loss: 0.5298 - val_auc: 0.5474 - lr: 0.0010\n","Epoch 3/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5273 - auc: 0.5494 - val_loss: 0.5238 - val_auc: 0.5734 - lr: 0.0010\n","Epoch 4/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5196 - auc: 0.5592 - val_loss: 0.5210 - val_auc: 0.5784 - lr: 0.0010\n","Epoch 5/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5160 - auc: 0.5676 - val_loss: 0.5192 - val_auc: 0.5768 - lr: 0.0010\n","Epoch 6/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5144 - auc: 0.5661 - val_loss: 0.5183 - val_auc: 0.5811 - lr: 0.0010\n","Epoch 7/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5137 - auc: 0.5707 - val_loss: 0.5191 - val_auc: 0.5792 - lr: 0.0010\n","Epoch 8/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5135 - auc: 0.5669 - val_loss: 0.5188 - val_auc: 0.5875 - lr: 0.0010\n","Epoch 9/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5135 - auc: 0.5635 - val_loss: 0.5169 - val_auc: 0.5849 - lr: 0.0010\n","Epoch 10/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5135 - auc: 0.5651 - val_loss: 0.5158 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 11/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5131 - auc: 0.5627 - val_loss: 0.5147 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 12/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5141 - auc: 0.5579 - val_loss: 0.5189 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 13/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5132 - auc: 0.5616 - val_loss: 0.5146 - val_auc: 0.5881 - lr: 0.0010\n","Epoch 14/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5125 - auc: 0.5700 - val_loss: 0.5126 - val_auc: 0.5886 - lr: 0.0010\n","Epoch 15/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5123 - auc: 0.5666 - val_loss: 0.5140 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 16/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5125 - auc: 0.5688 - val_loss: 0.5193 - val_auc: 0.5883 - lr: 9.0000e-04\n","Epoch 17/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5129 - auc: 0.5669 - val_loss: 0.5123 - val_auc: 0.5877 - lr: 9.0000e-04\n","Epoch 18/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5135 - auc: 0.5589 - val_loss: 0.5202 - val_auc: 0.5877 - lr: 9.0000e-04\n","Epoch 19/200\n","246/246 [==============================] - 2s 9ms/step - loss: 0.5120 - auc: 0.5710 - val_loss: 0.5241 - val_auc: 0.5880 - lr: 9.0000e-04\n","340/340 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 8 : 0.5897302345467994\n","\n","\n","########################## Fold 9 ##########################\n","x_train len:15462 shape:(15462, 15)\n","Epoch 1/200\n","242/242 [==============================] - 5s 11ms/step - loss: 0.6584 - auc: 0.5270 - val_loss: 0.5342 - val_auc: 0.5590 - lr: 0.0010\n","Epoch 2/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5538 - auc: 0.5353 - val_loss: 0.5212 - val_auc: 0.5519 - lr: 0.0010\n","Epoch 3/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5324 - auc: 0.5418 - val_loss: 0.5148 - val_auc: 0.5783 - lr: 0.0010\n","Epoch 4/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5242 - auc: 0.5596 - val_loss: 0.5126 - val_auc: 0.5798 - lr: 0.0010\n","Epoch 5/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5209 - auc: 0.5592 - val_loss: 0.5116 - val_auc: 0.5825 - lr: 0.0010\n","Epoch 6/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5195 - auc: 0.5681 - val_loss: 0.5107 - val_auc: 0.5824 - lr: 0.0010\n","Epoch 7/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5173 - auc: 0.5730 - val_loss: 0.5107 - val_auc: 0.5810 - lr: 0.0010\n","Epoch 8/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5174 - auc: 0.5703 - val_loss: 0.5086 - val_auc: 0.5789 - lr: 0.0010\n","Epoch 9/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5167 - auc: 0.5727 - val_loss: 0.5085 - val_auc: 0.5835 - lr: 0.0010\n","Epoch 10/200\n","242/242 [==============================] - 3s 14ms/step - loss: 0.5179 - auc: 0.5626 - val_loss: 0.5111 - val_auc: 0.5857 - lr: 0.0010\n","Epoch 11/200\n","242/242 [==============================] - 3s 13ms/step - loss: 0.5179 - auc: 0.5616 - val_loss: 0.5110 - val_auc: 0.5854 - lr: 0.0010\n","Epoch 12/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5170 - auc: 0.5686 - val_loss: 0.5073 - val_auc: 0.5850 - lr: 0.0010\n","Epoch 13/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5173 - auc: 0.5683 - val_loss: 0.5089 - val_auc: 0.5844 - lr: 0.0010\n","Epoch 14/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5167 - auc: 0.5702 - val_loss: 0.5133 - val_auc: 0.5851 - lr: 0.0010\n","Epoch 15/200\n","242/242 [==============================] - 2s 9ms/step - loss: 0.5161 - auc: 0.5709 - val_loss: 0.5075 - val_auc: 0.5799 - lr: 0.0010\n","Epoch 16/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5163 - auc: 0.5719 - val_loss: 0.5083 - val_auc: 0.5849 - lr: 9.0000e-04\n","Epoch 17/200\n","242/242 [==============================] - 2s 10ms/step - loss: 0.5169 - auc: 0.5690 - val_loss: 0.5104 - val_auc: 0.5841 - lr: 9.0000e-04\n","348/348 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 9 : 0.5855904352156261\n","\n","\n","########################## Fold 10 ##########################\n","x_train len:16115 shape:(16115, 15)\n","Epoch 1/200\n","252/252 [==============================] - 4s 11ms/step - loss: 0.6476 - auc: 0.5119 - val_loss: 0.5618 - val_auc: 0.5702 - lr: 0.0010\n","Epoch 2/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5520 - auc: 0.5277 - val_loss: 0.5329 - val_auc: 0.5686 - lr: 0.0010\n","Epoch 3/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5291 - auc: 0.5372 - val_loss: 0.5218 - val_auc: 0.5675 - lr: 0.0010\n","Epoch 4/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5199 - auc: 0.5598 - val_loss: 0.5181 - val_auc: 0.5831 - lr: 0.0010\n","Epoch 5/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5178 - auc: 0.5605 - val_loss: 0.5161 - val_auc: 0.5839 - lr: 0.0010\n","Epoch 6/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5173 - auc: 0.5591 - val_loss: 0.5135 - val_auc: 0.5833 - lr: 0.0010\n","Epoch 7/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5165 - auc: 0.5595 - val_loss: 0.5141 - val_auc: 0.5856 - lr: 0.0010\n","Epoch 8/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5157 - auc: 0.5654 - val_loss: 0.5116 - val_auc: 0.5895 - lr: 0.0010\n","Epoch 9/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5158 - auc: 0.5621 - val_loss: 0.5106 - val_auc: 0.5869 - lr: 0.0010\n","Epoch 10/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5144 - auc: 0.5680 - val_loss: 0.5158 - val_auc: 0.5877 - lr: 0.0010\n","Epoch 11/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5152 - auc: 0.5629 - val_loss: 0.5145 - val_auc: 0.5869 - lr: 0.0010\n","Epoch 12/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5157 - auc: 0.5600 - val_loss: 0.5092 - val_auc: 0.5877 - lr: 0.0010\n","Epoch 13/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5148 - auc: 0.5638 - val_loss: 0.5100 - val_auc: 0.5871 - lr: 0.0010\n","Epoch 14/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5149 - auc: 0.5684 - val_loss: 0.5111 - val_auc: 0.5870 - lr: 9.0000e-04\n","Epoch 15/200\n","252/252 [==============================] - 2s 9ms/step - loss: 0.5139 - auc: 0.5670 - val_loss: 0.5138 - val_auc: 0.5873 - lr: 9.0000e-04\n","327/327 [==============================] - 1s 2ms/step\n","650/650 [==============================] - 1s 2ms/step\n","\n","\n","AUC score Fold 10 : 0.5898751515216534\n","\n","\n","Done saving models into a binary file\n","\n","\n","CV AUC score: 0.5903305699409497\n"]}]},{"cell_type":"code","source":["# submission['failure'] = test_predictions\n","# submission[[\"id\", \"failure\"]].to_csv('0711257_submission.csv', index=False)\n","# submission.to_csv('0711257_submission.csv', index=False)"],"metadata":{"id":"hiakx_T5c4Fu","executionInfo":{"status":"ok","timestamp":1673342801506,"user_tz":-480,"elapsed":412,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["# tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=100, expand_nested=True)"],"metadata":{"id":"Nf2uNlvHUTbB","executionInfo":{"status":"ok","timestamp":1673340607571,"user_tz":-480,"elapsed":5,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["# pip freeze > requirements.txt"],"metadata":{"id":"YtHd4heWW7u8","executionInfo":{"status":"ok","timestamp":1673340607571,"user_tz":-480,"elapsed":5,"user":{"displayName":"長瀚葉","userId":"05334668312095169890"}}},"execution_count":72,"outputs":[]}]}